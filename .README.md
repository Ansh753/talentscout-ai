# ðŸš€ TalentScout AI Hiring Assistant

##  Project Overview
An intelligent, fully-local AI hiring assistant that screens tech candidates by collecting information and generating personalized technical questions. Built with **Mistral 7B via Ollama** - **100% free, zero API costs**.

##  Features

###  Smart AI Assistant
- **Local LLM Integration**: Mistral 7B running via Ollama
- **Context-Aware Conversations**: Natural dialog flow
- **Fallback System**: Works even if Ollama fails
- **Information Extraction**: Auto-parses candidate details

###  Complete Screening Process
1. **Name** â†’ 2. **Email** â†’ 3. **Phone** â†’ 4. **Experience** â†’ 5. **Position** â†’ 6. **Location** â†’ 7. **Tech Stack**
- **Real-time Progress Tracking**: Visual step indicator
- **Smart Validation**: Email format, experience parsing
- **Tech Stack Detection**: Auto-identifies 20+ technologies

###  Technical Assessment
- **Personalized Questions**: Based on candidate's tech stack
- **5 Question Categories**: Fundamentals, Problem-solving, System Design, DevOps, Learning
- **Professional Formatting**: Beautiful card-based display

###  Premium UI/UX
- **Black/Blue/Purple Theme**: Professional, modern design
- **Animated Chat Bubbles**: Smooth slide-in effects
- **Progress Visualization**: 7-step tracker with icons
- **Real-time Updates**: Sidebar shows collected information
- **Export Functionality**: Download candidate data as JSON

## Quick Start

### Prerequisites
- Windows 10/11 (or Mac/Linux)
- 8GB+ RAM (for Mistral 7B)
- Python 3.8+
- 5GB free storage

### Installation (5 minutes)
```bash
# 1. Install Ollama (one-time)
# Download from https://ollama.ai

# 2. Download Mistral model (one-time, 4.4GB)
ollama pull mistral:7b

# 3. Start Ollama server (keep running)
ollama serve

# 4. Install Python packages
pip install streamlit requests

# 5. Run the application
streamlit run app.py
# Opens at http://localhost:8501

# TalentScout AI Hiring Assistant

## Setup
1. Install Ollama from https://ollama.ai
2. Run: `ollama pull mistral:7b`
3. Run: `ollama serve` (keep running)
4. Install: `pip install streamlit requests`
5. Run: `streamlit run app.py`

## Features
- Local AI (Mistral 7B via Ollama)
- Collects candidate information
- Generates technical questions
- Beautiful UI

## Author
[Your Name] - AI/ML Intern Candidate